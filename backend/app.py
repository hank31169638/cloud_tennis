import os
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from werkzeug.utils import secure_filename
from apscheduler.schedulers.background import BackgroundScheduler
import uuid
import threading
import time

CWD = os.path.dirname(os.path.abspath(__file__))
APP_ROOT = CWD
UPLOAD_DIR = os.path.join(APP_ROOT, 'uploads')
DATA_DIR = os.path.join(APP_ROOT, 'data')
STATIC_FILES = APP_ROOT  # serve html/css from project root

os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(DATA_DIR, exist_ok=True)

# Let Flask serve static files from project root so pages work when served by the app
app = Flask(__name__, static_folder=STATIC_FILES)

# Configure CORS based on environment
allowed_origins = os.environ.get('ALLOWED_ORIGINS', '*')
if allowed_origins != '*':
    # æ”¯æ´å¤šå€‹åŸŸåï¼ˆé€—è™Ÿåˆ†éš”ï¼‰
    allowed_origins = [origin.strip() for origin in allowed_origins.split(',')]

CORS(app, origins=allowed_origins)  # allow cross-origin

# Initialize ranking crawler and scheduler
from crawler import TableTennisRankingCrawler
crawler = TableTennisRankingCrawler()

# Set up scheduler for auto-updating rankings every hour
scheduler = BackgroundScheduler()
scheduler.add_job(func=crawler.update_all_rankings, trigger="interval", hours=1)
scheduler.start()

# Global dictionary to store training tasks
training_tasks = {}


def run_training_task(task_id, config):
    """åœ¨èƒŒæ™¯åŸ·è¡Œè¨“ç·´ä»»å‹™"""
    try:
        training_tasks[task_id]['status'] = 'training'
        training_tasks[task_id]['message'] = 'æ­£åœ¨æº–å‚™è³‡æ–™...'
        training_tasks[task_id]['logs'] = []
        
        # å‹•æ…‹å°å…¥è¨“ç·´è…³æœ¬
        import train_web
        
        # åŸ·è¡Œè¨“ç·´ï¼ˆé€™æœƒæ›´æ–° training_tasks ä¸­çš„é€²åº¦ï¼‰
        result = train_web.train_model(config, task_id, training_tasks)
        
        training_tasks[task_id]['status'] = 'completed'
        training_tasks[task_id]['result'] = result
        training_tasks[task_id]['message'] = 'è¨“ç·´å®Œæˆï¼'
        
    except Exception as e:
        training_tasks[task_id]['status'] = 'failed'
        training_tasks[task_id]['message'] = str(e)
        training_tasks[task_id]['logs'].append(f"âŒ éŒ¯èª¤: {str(e)}")


@app.route('/')
def serve_index():
    return app.send_static_file('index.html')


@app.get('/health')
def health():
    return jsonify({'status': 'ok'})


# Alias for API consumers
@app.get('/api/health')
def api_health():
    return jsonify({'status': 'ok', 'message': 'Server is running'})


@app.route('/analyze.html')
def serve_analyze_page():
    return app.send_static_file('analyze.html')


@app.route('/stats.html')
def serve_stats_page():
    # this project uses player_data.html as the stats/player page
    return app.send_static_file('player_data.html')


@app.route('/index.css')
def serve_css():
    return app.send_static_file('index.css')


# NOTE: generic static route relocated to after API routes to avoid catching API calls


@app.post('/analyze')
def analyze_video():
    if 'file' not in request.files:
        return jsonify({'error': 'æ²’æœ‰æ”¶åˆ°æª”æ¡ˆæ¬„ä½ file'}), 400

    file = request.files['file']
    if not file or file.filename == '':
        return jsonify({'error': 'æœªé¸æ“‡æª”æ¡ˆ'}), 400

    filename = secure_filename(file.filename)
    save_path = os.path.join(UPLOAD_DIR, filename)
    try:
        file.save(save_path)
    except Exception as e:
        return jsonify({'error': f'ç„¡æ³•å„²å­˜æª”æ¡ˆ: {e}'}), 500

    try:
        # Lazy import to avoid heavy imports failing before server starts
        from user_movid_predict import predict_video  # noqa: WPS433
        result = predict_video(save_path)
        if not result:
            return jsonify({'error': 'åˆ†æå¤±æ•—æˆ–å›å‚³çµæœç‚ºç©º'}), 500

        # Normalize keys for frontend consumption
        return jsonify({
            'predicted_class': result.get('predicted_class'),
            'confidence': result.get('confidence'),
            'probabilities': result.get('probabilities', {}),
            'filename': filename
        })
    except Exception as e:
        return jsonify({'error': f'åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}'}), 500


# ============ Ranking API Routes (from cloud_tennis) ============

@app.route('/api/rankings/<category>', methods=['GET'])
def get_ranking(category):
    """
    å–å¾—ç‰¹å®šé¡åˆ¥çš„æ’åè³‡æ–™
    category: SEN_SINGLES, SEN_DOUBLES
    """
    valid_categories = ['SEN_SINGLES', 'SEN_DOUBLES']
    
    if category not in valid_categories:
        return jsonify({
            'error': 'ç„¡æ•ˆçš„é¡åˆ¥',
            'valid_categories': valid_categories
        }), 400
    
    # å…ˆå˜—è©¦è®€å–å·²å„²å­˜çš„è³‡æ–™
    data = crawler.load_data(category)
    
    # å¦‚æœæ²’æœ‰è³‡æ–™,ç«‹å³æŠ“å–
    if not data:
        print(f"é¦–æ¬¡æŠ“å– {category} è³‡æ–™...")
        raw_data = crawler.fetch_ranking(category)
        if raw_data:
            data = crawler.load_data(category)
    
    if data:
        # ç¯©é¸å‡º SubEventCode ç‚º MS æˆ– MD çš„é¸æ‰‹
        if 'data' in data and 'Result' in data['data']:
            original_result = data['data']['Result']
            
            # æ ¹æ“šé¡åˆ¥ç¯©é¸
            if category == 'SEN_SINGLES':
                # åªä¿ç•™ MS (ç”·å­å–®æ‰“)
                filtered_result = [
                    player for player in original_result 
                    if player.get('SubEventCode') == 'MS'
                ]
            elif category == 'SEN_DOUBLES':
                # åªä¿ç•™ MD (ç”·å­é›™æ‰“)
                filtered_result = [
                    player for player in original_result 
                    if player.get('SubEventCode') == 'MD'
                ]
            else:
                filtered_result = original_result
            
            # æŒ‰ç…§ CurrentRank æ’åº
            filtered_result.sort(key=lambda x: int(x.get('CurrentRank', 999999)))
            
            # æ›´æ–°è³‡æ–™
            data['data']['Result'] = filtered_result
            data['data']['TotalRecords'] = len(filtered_result)
        
        return jsonify(data), 200
    else:
        return jsonify({'error': 'ç„¡æ³•å–å¾—è³‡æ–™'}), 500


@app.route('/api/rankings', methods=['GET'])
def get_all_rankings():
    """å–å¾—æ‰€æœ‰æ’åè³‡æ–™"""
    categories = ['SEN_SINGLES', 'SEN_DOUBLES']
    all_data = {}
    
    for category in categories:
        data = crawler.load_data(category)
        if data:
            all_data[category] = data
    
    return jsonify(all_data), 200


@app.route('/api/update', methods=['POST'])
def manual_update():
    """æ‰‹å‹•è§¸ç™¼è³‡æ–™æ›´æ–°"""
    results = crawler.update_all_rankings()
    return jsonify({
        'message': 'æ›´æ–°å®Œæˆ',
        'results': results
    }), 200


@app.post('/api/train')
def start_training():
    """å•Ÿå‹•æ¨¡å‹è¨“ç·´"""
    try:
        config = request.get_json()
        
        # é©—è­‰é…ç½®
        required_fields = ['model_type', 'epochs', 'batch_size', 'learning_rate']
        for field in required_fields:
            if field not in config:
                return jsonify({'error': f'ç¼ºå°‘å¿…è¦åƒæ•¸: {field}'}), 400
        
        # ç”Ÿæˆä»»å‹™ ID
        task_id = str(uuid.uuid4())
        
        # åˆå§‹åŒ–ä»»å‹™ç‹€æ…‹
        training_tasks[task_id] = {
            'status': 'initializing',
            'message': 'æ­£åœ¨åˆå§‹åŒ–è¨“ç·´...',
            'config': config,
            'logs': [],
            'current_epoch': 0,
            'total_epochs': config['epochs']
        }
        
        # åœ¨èƒŒæ™¯åŸ·è¡Œç·’ä¸­å•Ÿå‹•è¨“ç·´
        training_thread = threading.Thread(
            target=run_training_task,
            args=(task_id, config)
        )
        training_thread.daemon = True
        training_thread.start()
        
        return jsonify({
            'task_id': task_id,
            'message': 'è¨“ç·´å·²å•Ÿå‹•'
        }), 200
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.get('/api/train/status/<task_id>')
def get_training_status(task_id):
    """å–å¾—è¨“ç·´ç‹€æ…‹"""
    if task_id not in training_tasks:
        return jsonify({'error': 'æ‰¾ä¸åˆ°è©²è¨“ç·´ä»»å‹™'}), 404
    
    task = training_tasks[task_id]
    
    # åªè¿”å›æœ€æ–°çš„æ—¥èªŒï¼ˆé¿å…å‚³è¼¸éå¤§ï¼‰
    recent_logs = task.get('logs', [])[-10:] if 'logs' in task else []
    
    response = {
        'status': task['status'],
        'message': task.get('message', ''),
        'current_epoch': task.get('current_epoch', 0),
        'total_epochs': task.get('total_epochs', 0),
        'accuracy': task.get('accuracy'),
        'val_accuracy': task.get('val_accuracy'),
        'loss': task.get('loss'),
        'val_loss': task.get('val_loss'),
        'logs': recent_logs
    }
    
    if task['status'] == 'completed':
        response['result'] = task.get('result', {})
    
    return jsonify(response), 200


# ============ Failure Analysis API Routes ============

@app.route('/api/analyze-failure', methods=['POST'])
def analyze_failure():
    """åˆ†æå¤±åˆ†å½±ç‰‡ä¸¦æä¾› AI å»ºè­°"""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'æ²’æœ‰æ”¶åˆ°æª”æ¡ˆæ¬„ä½ file'}), 400

        file = request.files['file']
        if not file or file.filename == '':
            return jsonify({'error': 'æœªé¸æ“‡æª”æ¡ˆ'}), 400

        # å„²å­˜å½±ç‰‡
        filename = secure_filename(file.filename)
        save_path = os.path.join(UPLOAD_DIR, f'failure_{uuid.uuid4()}_{filename}')
        file.save(save_path)

        # æ˜¯å¦ä½¿ç”¨ Gemini AI
        use_gemini = request.form.get('use_gemini', 'true').lower() == 'true'
        
        # åˆå§‹åŒ–åˆ†æå™¨
        from failure_analyzer import FailureAnalyzer
        analyzer = FailureAnalyzer()
        
        # åŸ·è¡Œåˆ†æ
        print(f"ğŸ¬ é–‹å§‹åˆ†æå¤±èª¤å½±ç‰‡: {filename}")
        result = analyzer.analyze_failure(save_path, use_gemini=use_gemini)
        
        # è¿”å›çµæœ
        return jsonify({
            'success': True,
            'filename': filename,
            'analysis': result,
            'video_path': save_path
        }), 200

    except Exception as e:
        print(f"âŒ åˆ†æå¤±æ•—: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/analyze-failure/batch', methods=['POST'])
def analyze_failure_batch():
    """æ‰¹æ¬¡åˆ†æå¤šå€‹å¤±èª¤å½±ç‰‡"""
    try:
        if 'files' not in request.files:
            return jsonify({'error': 'æ²’æœ‰æ”¶åˆ°æª”æ¡ˆæ¬„ä½ files'}), 400

        files = request.files.getlist('files')
        if not files or len(files) == 0:
            return jsonify({'error': 'æœªé¸æ“‡æª”æ¡ˆ'}), 400

        use_gemini = request.form.get('use_gemini', 'true').lower() == 'true'
        
        from failure_analyzer import FailureAnalyzer
        analyzer = FailureAnalyzer()
        
        results = []
        for file in files:
            if file and file.filename:
                filename = secure_filename(file.filename)
                save_path = os.path.join(UPLOAD_DIR, f'failure_{uuid.uuid4()}_{filename}')
                file.save(save_path)
                
                try:
                    analysis = analyzer.analyze_failure(save_path, use_gemini=use_gemini)
                    results.append({
                        'filename': filename,
                        'success': True,
                        'analysis': analysis
                    })
                except Exception as e:
                    results.append({
                        'filename': filename,
                        'success': False,
                        'error': str(e)
                    })
        
        return jsonify({
            'total': len(files),
            'results': results
        }), 200

    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/analyze-failure/config', methods=['GET'])
def get_analysis_config():
    """å–å¾—åˆ†æé…ç½®è³‡è¨Š"""
    try:
        # æª¢æŸ¥ Gemini API æ˜¯å¦å¯ç”¨ - å¯¦éš›åˆå§‹åŒ–åˆ†æå™¨ä¾†æ¸¬è©¦
        from failure_analyzer import FailureAnalyzer
        test_analyzer = FailureAnalyzer()
        gemini_available = test_analyzer.model is not None
        
        return jsonify({
            'gemini_available': gemini_available,
            'supported_formats': ['mp4', 'avi', 'mov', 'mkv'],
            'max_duration_seconds': 10,
            'recommended_duration_seconds': 4,
            'analysis_modes': {
                'basic': 'åŸºç¤åˆ†æï¼ˆåƒ…ä½¿ç”¨ MediaPipeï¼‰',
                'gemini': 'AI æ·±åº¦åˆ†æï¼ˆä½¿ç”¨ Geminiï¼‰'
            }
        }), 200

    except Exception as e:
        return jsonify({'error': str(e)}), 500


# Generic static file route: allow fetching other files (images, css, js) from repo root
@app.route('/<path:filename>')
def serve_static_other(filename: str):
    # Security: only serve files that exist under project root
    full_path = os.path.join(STATIC_FILES, filename)
    if os.path.exists(full_path) and os.path.commonpath([APP_ROOT, os.path.abspath(full_path)]) == APP_ROOT:
        return send_from_directory(STATIC_FILES, filename)
    return jsonify({'error': 'file not found'}), 404


if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    # Initialize ranking data on startup
    print("åˆå§‹åŒ–æ’åè³‡æ–™...")
    try:
        crawler.update_all_rankings()
    except Exception as e:
        print(f"åˆå§‹åŒ–æ’åè³‡æ–™å¤±æ•—: {e}")
    
    app.run(host='0.0.0.0', port=port, debug=True)

